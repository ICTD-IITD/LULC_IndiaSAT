{"cells":[{"cell_type":"markdown","metadata":{"id":"GpVtD6DoukJV"},"source":["# Set Coding Environment"]},{"cell_type":"markdown","metadata":{"id":"TDxZmjR3u5mp"},"source":["## Library installations"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ydq6MFpwu9gF"},"outputs":[],"source":["# !pip install geemap geopandas"]},{"cell_type":"markdown","metadata":{"id":"QCntwp7jvBZ-"},"source":["## Module Imports"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"Jkly4lhevDok","executionInfo":{"status":"ok","timestamp":1696927532178,"user_tz":-330,"elapsed":2779,"user":{"displayName":"ICTD IITD","userId":"11419946949516230456"}}},"outputs":[],"source":["# import geemap\n","# import geopandas as gpd\n","from pprint import pprint\n","import ee\n","from datetime import datetime, timedelta\n","import pandas as pd\n","import numpy as np\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import confusion_matrix\n","from datetime import datetime, timedelta\n","from dateutil.relativedelta import relativedelta"]},{"cell_type":"markdown","metadata":{"id":"346StWJBvHez"},"source":["## Mount Google Drive"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"p-9ixp6bvLS9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1696927509293,"user_tz":-330,"elapsed":42928,"user":{"displayName":"ICTD IITD","userId":"11419946949516230456"}},"outputId":"37559da7-49b9-4e29-8d91-87310aa463b0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"K7F0hFrdvOwH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1696927512545,"user_tz":-330,"elapsed":533,"user":{"displayName":"ICTD IITD","userId":"11419946949516230456"}},"outputId":"e24b7ae5-8767-4a8e-d6b3-6775af42ee17"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/LULC_Experiments_Chahat_Ananjan_Saketh\n"]}],"source":["cd /content/drive/MyDrive/LULC_Experiments_Chahat_Ananjan_Saketh"]},{"cell_type":"markdown","metadata":{"id":"FBg2jArDvSv3"},"source":["## Authenticate to Google Earth Engine"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"GXSXdKfivbFF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1696927567268,"user_tz":-330,"elapsed":30717,"user":{"displayName":"ICTD IITD","userId":"11419946949516230456"}},"outputId":"d9b46224-081c-46a7-fb38-5dd957286106"},"outputs":[{"output_type":"stream","name":"stdout","text":["To authorize access needed by Earth Engine, open the following URL in a web browser and follow the instructions. If the web browser does not start automatically, please manually browse the URL below.\n","\n","    https://code.earthengine.google.com/client-auth?scopes=https%3A//www.googleapis.com/auth/earthengine%20https%3A//www.googleapis.com/auth/devstorage.full_control&request_id=TlAfH9tmVpcZTVwv0bQdk8x8_mgkU5L_utYoo87hbb8&tc=9sxB-BsKMOFbK3rxTfWLvJPaKG_ptDGDJfdRHTUdhr8&cc=CwYFtm0jWY3wGOeHYpqq0UfAxhhzimkk3HfKib7pWkk\n","\n","The authorization workflow will generate a code, which you should paste in the box below.\n","Enter verification code: 4/1AfJohXkQu6JEIt3zzva5eI2TkCZG02WQmoBJ7QmuAEI7VDumUHbfozesU4o\n","\n","Successfully saved authorization token.\n"]}],"source":["ee.Authenticate() #Uncomment this whenever needed, once done usually not needed for 1-2 days"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"NK6QSWMvveBt","executionInfo":{"status":"ok","timestamp":1696927574369,"user_tz":-330,"elapsed":1362,"user":{"displayName":"ICTD IITD","userId":"11419946949516230456"}}},"outputs":[],"source":["ee.Initialize()"]},{"cell_type":"markdown","metadata":{"id":"WmgQ-9jMfSIE"},"source":["# FUNCTION DEFINITIONS"]},{"cell_type":"code","source":["def fill_empty_bands(image):\n","  band_names = image.bandNames()\n","  zero_img = image.select(0).multiply(0).rename('constant').toDouble()\n","  zero_img_masked = zero_img.updateMask(zero_img)\n","  image = ee.Algorithms.If(ee.List(band_names).contains(ee.String('VV')),image, ee.Image(image).addBands(zero_img_masked.select('constant').rename('VV')))\n","  image = ee.Algorithms.If(ee.List(band_names).contains(ee.String('VH')),image, ee.Image(image).addBands(zero_img_masked.select('constant').rename('VH')))\n","  return image\n","\n","\n","def Get_S1_ImageCollections(inputStartDate, inputEndDate, roi_boundary):\n","  S1 = ee.ImageCollection('COPERNICUS/S1_GRD') \\\n","         .filter(ee.Filter.eq('instrumentMode', 'IW')) \\\n","         .filterDate(inputStartDate, inputEndDate) \\\n","         .filterBounds(roi_boundary)\n","\n","  S1_processed = S1.map(fill_empty_bands)\n","  return S1_processed\n","\n","\n","def GetVV_VH_image_datewise(S1_ic):\n","  def get_VV_VH_datewise(date):\n","    zero_img = S1_ic.first().select('VV','VH').multiply(0)\n","    zero_img_masked = zero_img.updateMask(zero_img)\n","\n","    subset_ic = S1_ic.select(['VV','VH']).filterDate(ee.Date(date), ee.Date(date).advance(16, 'day'))\n","    image = ee.Algorithms.If( ee.Number(subset_ic.size()).gt(0), subset_ic.mean().set('system:time_start',ee.Date(date).millis()), zero_img.set('system:time_start',ee.Date(date).millis()))\n","\n","    return image\n","  return get_VV_VH_datewise\n","\n","\n","def Get_S1_16Day_VV_VH_TimeSeries(inputStartDate, inputEndDate, S1_ic):\n","  startDate = datetime.strptime(inputStartDate,\"%Y-%m-%d\")\n","  endDate = datetime.strptime(inputEndDate,\"%Y-%m-%d\")\n","\n","  date_list = pd.date_range(start=startDate, end=endDate, freq='16D').tolist()\n","  date_list = ee.List( [datetime.strftime(curr_date,\"%Y-%m-%d\") for curr_date in date_list] )\n","\n","  S1_TS =  ee.ImageCollection.fromImages(date_list.map(GetVV_VH_image_datewise(S1_ic)))\n","  return S1_TS\n","\n","\n","def add_timestamp(image):\n","  timeImage = image.metadata('system:time_start').rename('timestamp')\n","  timeImageMasked = timeImage.updateMask(image.mask().select(0))\n","  return image.addBands(timeImageMasked)\n","\n","\n","def performInterpolation(image):\n","  image = ee.Image(image)\n","  beforeImages = ee.List(image.get('before'))\n","  beforeMosaic = ee.ImageCollection.fromImages(beforeImages).mosaic()\n","  afterImages = ee.List(image.get('after'))\n","  afterMosaic = ee.ImageCollection.fromImages(afterImages).mosaic()\n","\n","  # Interpolation formula\n","  # y = y1 + (y2-y1)*((t – t1) / (t2 – t1))\n","  # y = interpolated image\n","  # y1 = before image\n","  # y2 = after image\n","  # t = interpolation timestamp\n","  # t1 = before image timestamp\n","  # t2 = after image timestamp\n","\n","  t1 = beforeMosaic.select('timestamp').rename('t1')\n","  t2 = afterMosaic.select('timestamp').rename('t2')\n","  t = image.metadata('system:time_start').rename('t')\n","  timeImage = ee.Image.cat([t1, t2, t])\n","  timeRatio = timeImage.expression('(t - t1) / (t2 - t1)', {\n","                  't': timeImage.select('t'),\n","                  't1': timeImage.select('t1'),\n","                  't2': timeImage.select('t2'),\n","              })\n","\n","  interpolated = beforeMosaic.add((afterMosaic.subtract(beforeMosaic).multiply(timeRatio)))\n","  result = image.unmask(interpolated)\n","\n","  #Saketh\n","  #For data points on either end of time-series\n","  #Before or After mosaics may still have gaps (owing to few/no images in the window)\n","  #Simply fill with after mosaic (for first few data points) and before mosaic (for last few datapoints)\n","  fill_value = ee.ImageCollection([beforeMosaic, afterMosaic]).mosaic()\n","  result = result.unmask(fill_value)\n","\n","  return result.copyProperties(image, ['system:time_start'])\n","\n","\n","def interpolate_timeseries(S1_TS):\n","  filtered = S1_TS.map(add_timestamp)\n","\n","  # Time window in which we are willing to look forward and backward for unmasked pixel in time series\n","  timeWindow = 120\n","\n","  # Define a maxDifference filter to find all images within the specified days. Convert days to milliseconds.\n","  millis = ee.Number(timeWindow).multiply(1000*60*60*24)\n","  # Filter says that pick only those timestamps which lie between the 2 timestamps not more than millis difference apart\n","  maxDiffFilter = ee.Filter.maxDifference(\n","                              difference = millis,\n","                              leftField = 'system:time_start',\n","                              rightField = 'system:time_start',\n","                            )\n","\n","  # Filter to find all images after a given image. Compare the image's timstamp against other images.\n","  # Images ahead of target image should have higher timestamp.\n","  lessEqFilter = ee.Filter.lessThanOrEquals(\n","                            leftField = 'system:time_start',\n","                            rightField = 'system:time_start'\n","                          )\n","\n","  # Similarly define this filter to find all images before a given image\n","  greaterEqFilter = ee.Filter.greaterThanOrEquals(\n","                            leftField = 'system:time_start',\n","                            rightField = 'system:time_start'\n","                          )\n","\n","  # Apply first join to find all images that are after the target image but within the timeWindow\n","  filter1 = ee.Filter.And( maxDiffFilter, lessEqFilter )\n","  join1 = ee.Join.saveAll(\n","                  matchesKey = 'after',\n","                  ordering = 'system:time_start',\n","                  ascending = False\n","          )\n","  join1Result = join1.apply(\n","                  primary = filtered,\n","                  secondary = filtered,\n","                  condition = filter1\n","                )\n","\n","  # Apply first join to find all images that are after the target image but within the timeWindow\n","  filter2 = ee.Filter.And( maxDiffFilter, greaterEqFilter )\n","  join2 = ee.Join.saveAll(\n","                  matchesKey = 'before',\n","                  ordering = 'system:time_start',\n","                  ascending = True\n","          )\n","  join2Result = join2.apply(\n","                  primary = join1Result,\n","                  secondary = join1Result,\n","                  condition = filter2\n","                )\n","\n","  interpolated_S1_TS = ee.ImageCollection(join2Result.map(performInterpolation))\n","\n","  return interpolated_S1_TS\n","\n","\n","def get_trained_model(training_data_assetpath):\n","  training_data = ee.FeatureCollection(training_data_assetpath)\n","\n","  # training_band_names = ['0_VH', '1_VH', '2_VH', '3_VH', '4_VH', '5_VH', '6_VH', '7_VH', '8_VH', '9_VH', '10_VH', '11_VH', '12_VH', '13_VH', '14_VH', '15_VH', '16_VH', '17_VH', '18_VH', '19_VH', '20_VH', '21_VH', '22_VH']\n","\n","  # training_band_names = ['0_VV', '1_VV', '2_VV', '3_VV', '4_VV', '5_VV', '6_VV', '7_VV', '8_VV', '9_VV', '10_VV', '11_VV', '12_VV', '13_VV', '14_VV', '15_VV', '16_VV', '17_VV', '18_VV', '19_VV', '20_VV', '21_VV', '22_VV']\n","\n","  training_band_names = ['0_VV', '1_VV', '2_VV', '3_VV', '4_VV', '5_VV', '6_VV', '7_VV', '8_VV', '9_VV', '10_VV', '11_VV', '12_VV', '13_VV', '14_VV', '15_VV', '16_VV', '17_VV', '18_VV', '19_VV', '20_VV', '21_VV', '22_VV',\n","                '0_VH', '1_VH', '2_VH', '3_VH', '4_VH', '5_VH', '6_VH', '7_VH', '8_VH', '9_VH', '10_VH', '11_VH', '12_VH', '13_VH', '14_VH', '15_VH', '16_VH', '17_VH', '18_VH', '19_VH', '20_VH', '21_VH', '22_VH']\n","\n","  trained_model = ee.Classifier.smileRandomForest(numberOfTrees=100, seed=42).setOutputMode('MULTIPROBABILITY').train(\n","                              features = training_data,\n","                            classProperty = 'class',\n","                            inputProperties = training_band_names )\n","\n","  return trained_model\n","\n","\n","def Get_SAR_TS_L2_Output(startDate, endDate, roi_boundary, trained_model):\n","  S1_ic = Get_S1_ImageCollections(startDate, endDate, roi_boundary)\n","\n","  S1_TS = Get_S1_16Day_VV_VH_TimeSeries(startDate, endDate, S1_ic)\n","  # pprint(S1_TS.first().bandNames().getInfo())\n","\n","  interpolated_S1_TS = interpolate_timeseries(S1_TS)\n","\n","  S1_TS_img = interpolated_S1_TS.toBands()\n","\n","  S1_VV_TS_img = S1_TS_img.select(['.*_VV'])\n","  S1_VH_TS_img = S1_TS_img.select(['.*_VH'])\n","\n","  training_band_names = ['0_VV', '1_VV', '2_VV', '3_VV', '4_VV', '5_VV', '6_VV', '7_VV', '8_VV', '9_VV', '10_VV', '11_VV', '12_VV', '13_VV', '14_VV', '15_VV', '16_VV', '17_VV', '18_VV', '19_VV', '20_VV', '21_VV', '22_VV',\n","                '0_VH', '1_VH', '2_VH', '3_VH', '4_VH', '5_VH', '6_VH', '7_VH', '8_VH', '9_VH', '10_VH', '11_VH', '12_VH', '13_VH', '14_VH', '15_VH', '16_VH', '17_VH', '18_VH', '19_VH', '20_VH', '21_VH', '22_VH']\n","\n","  training_img = S1_VV_TS_img.addBands(S1_VH_TS_img).select(training_band_names).clip(roi_boundary.geometry())\n","  classified_image = training_img.classify(trained_model)\n","\n","  roi_label_image = classified_image.select(['classification']).arrayArgmax().arrayFlatten([['Predicted_L2_Label']])\n","  roi_confidence_image = classified_image.select(['classification']).arrayGet(roi_label_image).rename(['confidence_L2'])\n","  roi_label_image = roi_label_image.add(5).toInt8()\n","\n","  LULC_image = roi_label_image.addBands(roi_confidence_image)\n","\n","  return LULC_image\n","\n","\n","def Get_slope(roi_boundary):\n","  dem = ee.Image('CGIAR/SRTM90_V4')\n","  slope = ee.Terrain.slope(dem)\n","  slope_image = slope.clip(roi_boundary.geometry())\n","  return slope_image"],"metadata":{"id":"Gm5Tp40veLer","executionInfo":{"status":"ok","timestamp":1696927587531,"user_tz":-330,"elapsed":633,"user":{"displayName":"ICTD IITD","userId":"11419946949516230456"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"j2PPhFbmce5Z"},"source":["# L2 LULC CLASSIFICATION"]},{"cell_type":"markdown","source":["## Take user input on ROI"],"metadata":{"id":"qYIr6onzgE1x"}},{"cell_type":"code","source":["# example- projects/ee-indiasat/assets/IndiaSat_test_polygons\n","# example- projects/ee-indiasat/assets/India_Boundary\n","# example- projects/ee-indiasat/assets/india_district_boundaries\n","# example- projects/ee-indiasat/assets/India_state_boundaries\n","# example- projects/ee-indiasat/assets/mandya_jaltol_boundary\n","# example- projects/ee-ananjan/assets/Wassan\n","roi_shapefile_path = input(\"\\n Enter the shapefile path containing your Region Of Interest (ROI): \\t\")\n","\n","choice = input(\"\\n Do you want to enter name of your ROI to filter within the shapefile?  \\n 1. Yes \\n 2. No \\n\")\n","\n","if choice == '1':\n","  roi_name = input(\"\\n Enter the name of your ROI : \\t\")\n","  filename_prefix = roi_name\n","else:\n","  roi_name = ''\n","  filename_prefix = input('\\nEnter the output filename prefix of your prediction maps (areaName): \\t')\n","\n","# Read the shapefile as feature collection\n","if roi_name == '':\n","  roi_boundary = ee.FeatureCollection(roi_shapefile_path)\n","else:\n","  roi_boundary = ee.FeatureCollection(roi_shapefile_path).filter(ee.Filter.eq('Name',roi_name))\n","\n","# pprint(roi_boundary.getInfo())"],"metadata":{"id":"-ooPu_ktgDza","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1696927614718,"user_tz":-330,"elapsed":15275,"user":{"displayName":"ICTD IITD","userId":"11419946949516230456"}},"outputId":"df376d8a-1767-4b78-ece7-189dc411e161"},"execution_count":8,"outputs":[{"name":"stdout","output_type":"stream","text":["\n"," Enter the shapefile path containing your Region Of Interest (ROI): \tprojects/ee-indiasat/assets/india_district_boundaries\n","\n"," Do you want to enter name of your ROI to filter within the shapefile?  \n"," 1. Yes \n"," 2. No \n","1\n","\n"," Enter the name of your ROI : \tBaran\n"]}]},{"cell_type":"code","source":["roi_boundary = ee.FeatureCollection('users/mtpictd/agro_eco_regions').filter(ee.Filter.eq('ae_regcode',13))\n","filename_prefix = 'EcoRegion13'"],"metadata":{"id":"L2D4sErQlhrq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["training_data_assetpath = 'projects/ee-indiasat/assets/Rasterized_Groundtruth/L2_TrainingData_SAR_TimeSeries_1Year'\n","trained_model = get_trained_model(training_data_assetpath)\n","\n","slope_img = Get_slope(roi_boundary)\n","\n","'''\n","INFERENCE CODE\n","'''\n","startDate = '2015-07-01'\n","endDate = '2022-07-01'\n","\n","loopStart = startDate\n","loopEnd = (datetime.strptime(endDate,\"%Y-%m-%d\")+relativedelta(years=1)).strftime(\"%Y-%m-%d\")\n","\n","while loopStart != loopEnd:\n","  currStartDate = datetime.strptime(loopStart,\"%Y-%m-%d\")\n","  currEndDate = (currStartDate+relativedelta(years=1)-timedelta(days=1)).strftime(\"%Y-%m-%d\")\n","  loopStart = (currStartDate+relativedelta(years=1)).strftime(\"%Y-%m-%d\")\n","\n","  currStartDate = currStartDate.strftime(\"%Y-%m-%d\")\n","\n","  print(\"\\n EXECUTING L2 LULC PREDICTION FOR \",currStartDate,\" TO \",currEndDate,\"\\n\")\n","\n","  curr_filename = filename_prefix + '_' + currStartDate + \"_\" + currEndDate\n","\n","  indiasat_ROI_LULC_image = Get_SAR_TS_L2_Output(currStartDate, currEndDate, roi_boundary, trained_model)\n","  combined_img = indiasat_ROI_LULC_image.addBands(slope_img)\n","\n","  #check if the slope is >20 deg, re-classify the pixel from cropland to non-cropland\n","  final_classified_img = combined_img.select(['Predicted_L2_Label']).where(\n","                                              combined_img.select('Predicted_L2_Label').eq(5)\n","                                              .And(\n","                                                    combined_img.select('slope').gte(30)\n","                                            ),\n","                                      6\n","                                  )\n","\n","  final_classified_img = final_classified_img.addBands(combined_img.select(['confidence_L2']))\n","  scale = 30\n","  # final_output_filename = curr_filename+'_Level2_LULCmap_'+str(scale)+'m'\n","  final_output_filename = curr_filename+'_Level2_LULCmap_'+str(scale)+'m'\n","  final_output_assetid = 'projects/ee-indiasat/assets/LULC_Deliverables_WithConfidence/Modified/' + final_output_filename\n","\n","  # Setup the task\n","  image_export_task = ee.batch.Export.image.toAsset(\n","    image = final_classified_img.clip(roi_boundary.geometry()),\n","    description = final_output_filename,\n","    assetId = final_output_assetid,\n","    pyramidingPolicy = {'Predicted_L2_Label': 'mode'},\n","    scale = scale,\n","    maxPixels = 1e13,\n","    crs = 'EPSG:4326'\n","  )\n","\n","  image_export_task.start()\n"],"metadata":{"id":"EuFer9_mfxWi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1696927625896,"user_tz":-330,"elapsed":4000,"user":{"displayName":"ICTD IITD","userId":"11419946949516230456"}},"outputId":"fec12d8c-e060-4a74-ba5b-bb4a6ddbae33"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["\n"," EXECUTING L2 LULC PREDICTION FOR  2015-07-01  TO  2016-06-30 \n","\n","\n"," EXECUTING L2 LULC PREDICTION FOR  2016-07-01  TO  2017-06-30 \n","\n","\n"," EXECUTING L2 LULC PREDICTION FOR  2017-07-01  TO  2018-06-30 \n","\n","\n"," EXECUTING L2 LULC PREDICTION FOR  2018-07-01  TO  2019-06-30 \n","\n","\n"," EXECUTING L2 LULC PREDICTION FOR  2019-07-01  TO  2020-06-30 \n","\n","\n"," EXECUTING L2 LULC PREDICTION FOR  2020-07-01  TO  2021-06-30 \n","\n","\n"," EXECUTING L2 LULC PREDICTION FOR  2021-07-01  TO  2022-06-30 \n","\n","\n"," EXECUTING L2 LULC PREDICTION FOR  2022-07-01  TO  2023-06-30 \n","\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"yWyXI-humA1q"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}